{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque de importación de bibliotecas para realizar el modelo predictivo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del dataset obtenido desde Kraggle\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar si el dataset tiene datos \"null\" y dropear filas duplicadas\n",
    "\n",
    "df.isnull().sum()\n",
    "df.drop_duplicates(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96146 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   gender               96146 non-null  object \n",
      " 1   age                  96146 non-null  float64\n",
      " 2   hypertension         96146 non-null  int64  \n",
      " 3   heart_disease        96146 non-null  int64  \n",
      " 4   smoking_history      96146 non-null  object \n",
      " 5   bmi                  96146 non-null  float64\n",
      " 6   HbA1c_level          96146 non-null  float64\n",
      " 7   blood_glucose_level  96146 non-null  int64  \n",
      " 8   diabetes             96146 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# De acá se observa que algunas variables del dataset no son numéricas, como: \"gender\" y \"smoking_history\" por lo que deben ser encodeadas para realizar la predicción\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    56161\n",
       "Male      39967\n",
       "Other        18\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se observan los valores de las dos variables en cuestión para realizar el mapeo correspondiente a los niveles observados\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never          34398\n",
       "No Info        32887\n",
       "former          9299\n",
       "current         9197\n",
       "not current     6367\n",
       "ever            3998\n",
       "Name: smoking_history, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smoking_history'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza el mapeo y encode de las dos variables a transformar\n",
    "\n",
    "labelEncode = pp.LabelEncoder()\n",
    "\n",
    "genderMap = {'Female': 0, 'Male': 1, 'Other': 2}\n",
    "df['gender'] = df['gender'].map(genderMap)\n",
    "\n",
    "smokingHistoryMap = {'never': 0, 'No Info': 1, 'current': 2, 'former': 3, 'ever': 4, 'not current': 5}\n",
    "df['smoking_history'] = df['smoking_history'].map(smokingHistoryMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "      <td>96146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.416065</td>\n",
       "      <td>41.794326</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>1.320960</td>\n",
       "      <td>27.321461</td>\n",
       "      <td>5.532609</td>\n",
       "      <td>138.218231</td>\n",
       "      <td>0.088220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493287</td>\n",
       "      <td>22.462948</td>\n",
       "      <td>0.267544</td>\n",
       "      <td>0.197833</td>\n",
       "      <td>1.473466</td>\n",
       "      <td>6.767716</td>\n",
       "      <td>1.073232</td>\n",
       "      <td>40.909771</td>\n",
       "      <td>0.283616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.860000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.690000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender           age  hypertension  heart_disease  \\\n",
       "count  96146.000000  96146.000000  96146.000000   96146.000000   \n",
       "mean       0.416065     41.794326      0.077601       0.040803   \n",
       "std        0.493287     22.462948      0.267544       0.197833   \n",
       "min        0.000000      0.080000      0.000000       0.000000   \n",
       "25%        0.000000     24.000000      0.000000       0.000000   \n",
       "50%        0.000000     43.000000      0.000000       0.000000   \n",
       "75%        1.000000     59.000000      0.000000       0.000000   \n",
       "max        2.000000     80.000000      1.000000       1.000000   \n",
       "\n",
       "       smoking_history           bmi   HbA1c_level  blood_glucose_level  \\\n",
       "count     96146.000000  96146.000000  96146.000000         96146.000000   \n",
       "mean          1.320960     27.321461      5.532609           138.218231   \n",
       "std           1.473466      6.767716      1.073232            40.909771   \n",
       "min           0.000000     10.010000      3.500000            80.000000   \n",
       "25%           0.000000     23.400000      4.800000           100.000000   \n",
       "50%           1.000000     27.320000      5.800000           140.000000   \n",
       "75%           2.000000     29.860000      6.200000           159.000000   \n",
       "max           5.000000     95.690000      9.000000           300.000000   \n",
       "\n",
       "           diabetes  \n",
       "count  96146.000000  \n",
       "mean       0.088220  \n",
       "std        0.283616  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se observan las métricas descriptivas para el dataset, además se ve que el valor mínimo para la edad es 0.08, por lo cuál es un valor \"inválido\" en este caso para la edad\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se remueven los valores que no tienen sentido en este caso de la edad\n",
    "df = df[df['age'].mod(1) == 0]\n",
    "# Luego se puede volver a ejecutar la celda anterior para ver que efectivamente se removieron los valores no válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teniendo los datos ya preparados, se splitean los datos en los conjuntos para comenzar a entrenar los modelos predictivos\n",
    "\n",
    "# Van todas las variables para predecir si se tiene diabetes o no\n",
    "x = df.iloc[:,:-1].values\n",
    "\n",
    "# Target\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "# Se separan los datos en 80% para entrenamiento y 20% para evaluación\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)\n",
    "\n",
    "# Se realiza el featuring scaling para normalizar los datos\n",
    "norm = pp.StandardScaler()\n",
    "x_train = norm.fit_transform(x_train)\n",
    "x_test = norm.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9594199819408297\n"
     ]
    }
   ],
   "source": [
    "# Se revisan algunos métodos predictivos\n",
    "# KNeighborsClassifier (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9579858713549689\n"
     ]
    }
   ],
   "source": [
    "# SVM Lineal (Linear SVM)\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515589313220375\n"
     ]
    }
   ],
   "source": [
    "# Árbol de clasificación (DecisionTreeClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672810325596218\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "forest.fit(x_train, y_train)\n",
    "y_pred = forest.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2354/2354 [==============================] - 2s 577us/step - loss: 0.1730 - accuracy: 0.9412\n",
      "Epoch 2/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1220 - accuracy: 0.9568\n",
      "Epoch 3/100\n",
      "2354/2354 [==============================] - 1s 570us/step - loss: 0.1205 - accuracy: 0.9576\n",
      "Epoch 4/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.1195 - accuracy: 0.9579\n",
      "Epoch 5/100\n",
      "2354/2354 [==============================] - 1s 580us/step - loss: 0.1183 - accuracy: 0.9580\n",
      "Epoch 6/100\n",
      "2354/2354 [==============================] - 1s 576us/step - loss: 0.1160 - accuracy: 0.9584\n",
      "Epoch 7/100\n",
      "2354/2354 [==============================] - 1s 587us/step - loss: 0.1138 - accuracy: 0.9591\n",
      "Epoch 8/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1117 - accuracy: 0.9591\n",
      "Epoch 9/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.1103 - accuracy: 0.9596\n",
      "Epoch 10/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1094 - accuracy: 0.9606\n",
      "Epoch 11/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.1087 - accuracy: 0.9608\n",
      "Epoch 12/100\n",
      "2354/2354 [==============================] - 1s 578us/step - loss: 0.1081 - accuracy: 0.9614\n",
      "Epoch 13/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1074 - accuracy: 0.9619\n",
      "Epoch 14/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.1071 - accuracy: 0.9620\n",
      "Epoch 15/100\n",
      "2354/2354 [==============================] - 1s 575us/step - loss: 0.1068 - accuracy: 0.9622\n",
      "Epoch 16/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1064 - accuracy: 0.9623\n",
      "Epoch 17/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.1060 - accuracy: 0.9628\n",
      "Epoch 18/100\n",
      "2354/2354 [==============================] - 1s 578us/step - loss: 0.1058 - accuracy: 0.9626\n",
      "Epoch 19/100\n",
      "2354/2354 [==============================] - 1s 582us/step - loss: 0.1054 - accuracy: 0.9630\n",
      "Epoch 20/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.1050 - accuracy: 0.9629\n",
      "Epoch 21/100\n",
      "2354/2354 [==============================] - 1s 577us/step - loss: 0.1049 - accuracy: 0.9634\n",
      "Epoch 22/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1046 - accuracy: 0.9633\n",
      "Epoch 23/100\n",
      "2354/2354 [==============================] - 1s 569us/step - loss: 0.1043 - accuracy: 0.9635\n",
      "Epoch 24/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.1041 - accuracy: 0.9633\n",
      "Epoch 25/100\n",
      "2354/2354 [==============================] - 1s 569us/step - loss: 0.1040 - accuracy: 0.9636\n",
      "Epoch 26/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1036 - accuracy: 0.9639\n",
      "Epoch 27/100\n",
      "2354/2354 [==============================] - 1s 575us/step - loss: 0.1035 - accuracy: 0.9638\n",
      "Epoch 28/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.1035 - accuracy: 0.9637\n",
      "Epoch 29/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.1034 - accuracy: 0.9638\n",
      "Epoch 30/100\n",
      "2354/2354 [==============================] - 1s 570us/step - loss: 0.1032 - accuracy: 0.9636\n",
      "Epoch 31/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.1030 - accuracy: 0.9640\n",
      "Epoch 32/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.1030 - accuracy: 0.9638\n",
      "Epoch 33/100\n",
      "2354/2354 [==============================] - 1s 563us/step - loss: 0.1029 - accuracy: 0.9639\n",
      "Epoch 34/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.1026 - accuracy: 0.9640\n",
      "Epoch 35/100\n",
      "2354/2354 [==============================] - 1s 563us/step - loss: 0.1025 - accuracy: 0.9641\n",
      "Epoch 36/100\n",
      "2354/2354 [==============================] - 1s 570us/step - loss: 0.1024 - accuracy: 0.9640\n",
      "Epoch 37/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1020 - accuracy: 0.9642\n",
      "Epoch 38/100\n",
      "2354/2354 [==============================] - 1s 565us/step - loss: 0.1020 - accuracy: 0.9644\n",
      "Epoch 39/100\n",
      "2354/2354 [==============================] - 1s 570us/step - loss: 0.1016 - accuracy: 0.9644\n",
      "Epoch 40/100\n",
      "2354/2354 [==============================] - 1s 567us/step - loss: 0.1014 - accuracy: 0.9647\n",
      "Epoch 41/100\n",
      "2354/2354 [==============================] - 1s 563us/step - loss: 0.1012 - accuracy: 0.9644\n",
      "Epoch 42/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.1010 - accuracy: 0.9647\n",
      "Epoch 43/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.1008 - accuracy: 0.9646\n",
      "Epoch 44/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.1007 - accuracy: 0.9645\n",
      "Epoch 45/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.1004 - accuracy: 0.9647\n",
      "Epoch 46/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.1003 - accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.0998 - accuracy: 0.9651\n",
      "Epoch 48/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.0999 - accuracy: 0.9649\n",
      "Epoch 49/100\n",
      "2354/2354 [==============================] - 1s 576us/step - loss: 0.0994 - accuracy: 0.9647\n",
      "Epoch 50/100\n",
      "2354/2354 [==============================] - 1s 567us/step - loss: 0.0992 - accuracy: 0.9653\n",
      "Epoch 51/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.0989 - accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "2354/2354 [==============================] - 1s 570us/step - loss: 0.0986 - accuracy: 0.9649\n",
      "Epoch 53/100\n",
      "2354/2354 [==============================] - 1s 568us/step - loss: 0.0985 - accuracy: 0.9653\n",
      "Epoch 54/100\n",
      "2354/2354 [==============================] - 1s 577us/step - loss: 0.0981 - accuracy: 0.9652\n",
      "Epoch 55/100\n",
      "2354/2354 [==============================] - 1s 569us/step - loss: 0.0981 - accuracy: 0.9653\n",
      "Epoch 56/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.0977 - accuracy: 0.9655\n",
      "Epoch 57/100\n",
      "2354/2354 [==============================] - 1s 567us/step - loss: 0.0972 - accuracy: 0.9657\n",
      "Epoch 58/100\n",
      "2354/2354 [==============================] - 1s 567us/step - loss: 0.0973 - accuracy: 0.9660\n",
      "Epoch 59/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.0967 - accuracy: 0.9659\n",
      "Epoch 60/100\n",
      "2354/2354 [==============================] - 1s 567us/step - loss: 0.0966 - accuracy: 0.9661\n",
      "Epoch 61/100\n",
      "2354/2354 [==============================] - 1s 569us/step - loss: 0.0965 - accuracy: 0.9663\n",
      "Epoch 62/100\n",
      "2354/2354 [==============================] - 1s 565us/step - loss: 0.0965 - accuracy: 0.9661\n",
      "Epoch 63/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.0960 - accuracy: 0.9665\n",
      "Epoch 64/100\n",
      "2354/2354 [==============================] - 1s 579us/step - loss: 0.0959 - accuracy: 0.9664\n",
      "Epoch 65/100\n",
      "2354/2354 [==============================] - 1s 566us/step - loss: 0.0958 - accuracy: 0.9666\n",
      "Epoch 66/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.0957 - accuracy: 0.9668\n",
      "Epoch 67/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.0955 - accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "2354/2354 [==============================] - 1s 569us/step - loss: 0.0953 - accuracy: 0.9669\n",
      "Epoch 69/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.0953 - accuracy: 0.9666\n",
      "Epoch 70/100\n",
      "2354/2354 [==============================] - 1s 562us/step - loss: 0.0950 - accuracy: 0.9672\n",
      "Epoch 71/100\n",
      "2354/2354 [==============================] - 1s 568us/step - loss: 0.0947 - accuracy: 0.9671\n",
      "Epoch 72/100\n",
      "2354/2354 [==============================] - 1s 558us/step - loss: 0.0946 - accuracy: 0.9673\n",
      "Epoch 73/100\n",
      "2354/2354 [==============================] - 1s 558us/step - loss: 0.0942 - accuracy: 0.9675\n",
      "Epoch 74/100\n",
      "2354/2354 [==============================] - 1s 562us/step - loss: 0.0939 - accuracy: 0.9675\n",
      "Epoch 75/100\n",
      "2354/2354 [==============================] - 1s 561us/step - loss: 0.0936 - accuracy: 0.9678\n",
      "Epoch 76/100\n",
      "2354/2354 [==============================] - 1s 562us/step - loss: 0.0934 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "2354/2354 [==============================] - 1s 558us/step - loss: 0.0930 - accuracy: 0.9682\n",
      "Epoch 78/100\n",
      "2354/2354 [==============================] - 1s 560us/step - loss: 0.0926 - accuracy: 0.9684\n",
      "Epoch 79/100\n",
      "2354/2354 [==============================] - 1s 571us/step - loss: 0.0923 - accuracy: 0.9687\n",
      "Epoch 80/100\n",
      "2354/2354 [==============================] - 1s 574us/step - loss: 0.0920 - accuracy: 0.9687\n",
      "Epoch 81/100\n",
      "2354/2354 [==============================] - 1s 581us/step - loss: 0.0917 - accuracy: 0.9690\n",
      "Epoch 82/100\n",
      "2354/2354 [==============================] - 1s 575us/step - loss: 0.0919 - accuracy: 0.9688\n",
      "Epoch 83/100\n",
      "2354/2354 [==============================] - 1s 578us/step - loss: 0.0915 - accuracy: 0.9689\n",
      "Epoch 84/100\n",
      "2354/2354 [==============================] - 1s 579us/step - loss: 0.0913 - accuracy: 0.9689\n",
      "Epoch 85/100\n",
      "2354/2354 [==============================] - 1s 566us/step - loss: 0.0912 - accuracy: 0.9690\n",
      "Epoch 86/100\n",
      "2354/2354 [==============================] - 1s 573us/step - loss: 0.0910 - accuracy: 0.9688\n",
      "Epoch 87/100\n",
      "2354/2354 [==============================] - 1s 568us/step - loss: 0.0912 - accuracy: 0.9692\n",
      "Epoch 88/100\n",
      "2354/2354 [==============================] - 1s 567us/step - loss: 0.0910 - accuracy: 0.9689\n",
      "Epoch 89/100\n",
      "2354/2354 [==============================] - 1s 565us/step - loss: 0.0908 - accuracy: 0.9690\n",
      "Epoch 90/100\n",
      "2354/2354 [==============================] - 1s 564us/step - loss: 0.0909 - accuracy: 0.9692\n",
      "Epoch 91/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.0910 - accuracy: 0.9693\n",
      "Epoch 92/100\n",
      "2354/2354 [==============================] - 1s 563us/step - loss: 0.0911 - accuracy: 0.9691\n",
      "Epoch 93/100\n",
      "2354/2354 [==============================] - 1s 568us/step - loss: 0.0906 - accuracy: 0.9693\n",
      "Epoch 94/100\n",
      "2354/2354 [==============================] - 1s 563us/step - loss: 0.0906 - accuracy: 0.9691\n",
      "Epoch 95/100\n",
      "2354/2354 [==============================] - 1s 576us/step - loss: 0.0906 - accuracy: 0.9692\n",
      "Epoch 96/100\n",
      "2354/2354 [==============================] - 1s 569us/step - loss: 0.0906 - accuracy: 0.9694\n",
      "Epoch 97/100\n",
      "2354/2354 [==============================] - 1s 563us/step - loss: 0.0905 - accuracy: 0.9693\n",
      "Epoch 98/100\n",
      "2354/2354 [==============================] - 1s 572us/step - loss: 0.0903 - accuracy: 0.9695\n",
      "Epoch 99/100\n",
      "2354/2354 [==============================] - 1s 566us/step - loss: 0.0903 - accuracy: 0.9693\n",
      "Epoch 100/100\n",
      "2354/2354 [==============================] - 1s 564us/step - loss: 0.0902 - accuracy: 0.9695\n",
      "589/589 [==============================] - 0s 426us/step\n",
      "0.9696712168693897\n"
     ]
    }
   ],
   "source": [
    "# ANN (Artificial Neural Network)\n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) \n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(x_train, y_train, batch_size=32, epochs = 100)\n",
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "ejemplo = norm.transform([[1,21.0, 0,0,2,1,6, 94]]) \n",
    "prediccion = ann.predict(ejemplo)\n",
    "prediccion = (prediccion > 0.5)\n",
    "print(prediccion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
